{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling for Bayesian models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways and objectives from notebooks 3a-3e\n",
    "\n",
    "Sampling is a non-trivial approach to model inference and parameter estimation.  We will build our understanding of sampling algorithms from scratch starting with how to compute expectations of functions from distributions from which we don't know how to draw samples (using **importance sampling**) and then building on these ideas with **rejection sampling** which introduces the key idea of not accepting all samples.  We will finish with sampling from multi-dimensional models using the **Metropolis algorithm**.  Each step will be supported with exercises and code. We will examine the advantages and drawbacks of each method.\n",
    "\n",
    "Finally, we will briefly touch on modern MCMC methods which resolve some of the drawbacks including HMC, ADVI and NUTS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Approaches for Bayesian Computation\n",
    "\n",
    "Since analysis is off the table, a reasonable alternative is to attempt to estimate the integral using numerical methods. For example, consider the expected value of a random variable $\\mathbf{x}$:\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\begin{split}E[{\\bf x}] = \\int {\\bf x} f({\\bf x}) d{\\bf x}, \\qquad\n",
    "{\\bf x} = \\{x_1,...,x_k\\}\\end{split}\\notag\\\\\\begin{split}\\end{split}\\notag\\end{gathered}$$\n",
    "\n",
    "where $f({\\bf x})$ is the probability density of $\\bf x$ and $k$ (the dimension of vector $x$) is perhaps very large. If we can produce a reasonable number of random vectors $\\{{\\bf x_i}\\}$, we can use these values to approximate the unknown integral. This process is known as *Monte Carlo integration*. In general, MC integration allows integrals against probability density functions:\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\begin{split}I = \\int h(\\mathbf{x}) f(\\mathbf{x}) \\mathbf{dx}\\end{split}\\notag\\\\\\begin{split}\\end{split}\\notag\\end{gathered}$$\n",
    "\n",
    "to be estimated by finite sums:\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\begin{split}\\hat{I} = \\frac{1}{n}\\sum_{i=1}^n h(\\mathbf{x}_i),\\end{split}\\notag\\\\\\begin{split}\\end{split}\\notag\\end{gathered}$$\n",
    "\n",
    "where $\\mathbf{x}_i$ is a sample from $f$. This estimate is valid and useful because:\n",
    "\n",
    "-   By the strong law of large numbers:\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\begin{split}\\hat{I} \\rightarrow I   \\mbox{   with probability 1}\\end{split}\\notag\\\\\\begin{split}\\end{split}\\notag\\end{gathered}$$\n",
    "\n",
    "-   Simulation error can be measured and controlled:\n",
    "\n",
    "$$Var(\\hat{I}) = \\frac{1}{n(n-1)}\\sum_{i=1}^n\n",
    "   (h(\\mathbf{x}_i)-\\hat{I})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to perform the above computations, we need to be able to draw samples from the density $f({\\bf x})$, which is typically not the case, so the analysis is theoretical but cannot be applied as-is in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook 3b\n",
    "In this notebook, we shall see how to estimate the above when we cannot sample from $f(x)$.  To this end we will design a distribution $q(x)$ from which we know how to sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook 3c\n",
    "Further, we will see how to build a sampler from such a distribution $f({\\bf x})$ so that we can draw random samples from the distribution $f({\\bf x})$.  Note that this is in some sense more powerful that being able to only compute expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is this relevant to Bayesian analysis? \n",
    "\n",
    "When we observe data $y$ that we hypothesize as being obtained from a sampling model $f(y|\\theta)$, where $\\theta$ is a vector of (unknown) model parameters, a Bayesian places a *prior* distribution $p(\\theta)$ on the parameters to describe the uncertainty in the true values of the parameters. Bayesian inference, then, is obtained by calculating the *posterior* distribution, which is proportional to the product of these quantities:\n",
    "\n",
    "$$p(\\theta | y) \\propto f(y|\\theta) p(\\theta)$$\n",
    "\n",
    "unfortunately, for most problems of interest, the normalizing constant cannot be calculated because it involves mutli-dimensional integration over $\\theta$.\n",
    "\n",
    "Returning to our integral for MC sampling, if we replace $f(\\mathbf{x})$\n",
    "with a posterior, $p(\\theta|y)$ and make $h(\\theta)$ an interesting function of the unknown parameter, the resulting expectation is that of the posterior of $h(\\theta)$:\n",
    "\n",
    "$$E[h(\\theta)|y] = \\int h(\\theta) p(\\theta|y) d\\theta \\approx \\frac{1}{n}\\sum_{i=1}^n h(\\theta_i)$$\n",
    "\n",
    "We also require integrals to obtain marginal estimates from a joint model. If $\\theta$ is of length $K$, then inference about any particular parameter is obtained by:\n",
    "\n",
    "$$p(\\theta_i|y) \\propto \\int p(\\theta|y) d\\theta_{-i}$$\n",
    "\n",
    "where the `-i` subscript indicates all elements except the $i^{th}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that we can apply the techniques we discussed to Bayesian models by simply considering the likelihodd prior product $f(y|\\theta) p(\\theta)$ to be the density of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation for Markov Chain Monte Carlo\n",
    "However, even with the above techniques, sampling from multidimensional distributions becomes hard pretty quickly in the sense that many samples have very low probability density.  Thus it will take a long time for our sampler to converge.  This is discussed briefly in [Ian Murray's talk](http://videolectures.net/mlss09uk_murray_mcmc/)\n",
    "\n",
    "Markov Chain Monte Carlo tries to attack the problem by constructing a biased random walk that preferentially stays in regions of high density so that once we get a good sample, we tend to explore the region around it. This helps us sample the distribution in a more effective way.\n",
    "\n",
    "#### Notebook 3d\n",
    "We will explore this motivation for Markov Chain constructions instead of pure Monte Carlo approaches. We will also examine the Metropolis method, code it and understand its failure modes.\n",
    "\n",
    "#### Notebook 3e\n",
    "We will learn about advanced algorithms for MCMC and study their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Ian Murray, Markov Chain Monte Carlo, Videolecture.net [talk](http://videolectures.net/mlss09uk_murray_mcmc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
