{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MCMC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways and objectives from this notebook\n",
    "1. The concept of Gibbs sampling using full conditional distributions. When is Gibbs sampling suitable?\n",
    "2. Combining Gibbs and Metropolis: Metropolis-within-Gibbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs sampling\n",
    "So-far we have seen the Metropolis algorithm as the workhorse of sampling from a posterior distribution.  Another method of accomplishing the same is Gibbs sampling, which rests on different justifications and has different properties.\n",
    "\n",
    "Gibbs sampling is the method of sampling from *full conditional posteriors*, so we need to compute the conditional distribution of each variable given the others and sample from that.\n",
    "\n",
    "The algorithm for round robin Gibbs assuming that our state vector has $n$ variables $\\mathbf{x}^{(t)} = [x_1^{(t)}, x_2^{(t)}, ..., x_n^{(t)}]$, the Gibbs sampler proceeds to sample $\\mathbf{x}^{(t+1)}$ as follows:\n",
    "\n",
    "1. Sample $x_1^{(t+1)}$ from $p(x_1^{(t+1)} \\mid x_2^{(t)}, ..., x_n^{(t)})$,\n",
    "2. Sample $x_2^{(t+1)}$ from $p(x_2^{(t+1)} \\mid x_1^{(t+1)}, x_2^{(t)}, ..., x_n^{(t)})$\n",
    "3. ...\n",
    "4. Sample $x_i^{(t+1)}$ from $p(x_i^{(t+1)} \\mid x_1^{(t+1)}, ..., x_{i-1}^{(t+1)}, x_{i+1}^{(t)}, ..., x_n^{(t)})$\n",
    "5. ...\n",
    "6. Sample $x_n^{(t+1)}$ from $p(x_n^{(t+1)} \\mid x_2^{(t+1)}, ..., x_{n-1}^{(t+1)}$.\n",
    "\n",
    "We then set $\\mathbf{x}^{(t+1)} = [x_1^{(t+1)}, ..., x_{n-1}^{(t+1)}]$, as expected. So theoretically the algorithm is very simple.  Programmatically we can think of the algorithm as going through the variables from first to last and updating them in-place.  On the $i$-th variable, we simply use all the updated values for variables $0..i-1$.\n",
    "\n",
    "Alternatively, we can also use the *random scan Gibbs* sampling algorithm, which proceeds as follows:\n",
    "1. Pick index $i$ uniformly at random from $1,...,n$,\n",
    "2. Sample $x_i^{(t+1)}$ from $p(x_i^{(t+1)} \\mid x_1^{(t+1)}, ..., x_{i-1}^{(t+1)}, x_{i+1}^{(t)}, ..., x_n^{(t)}),$\n",
    "3. Set $\\mathbf{x}^{(t+1)} = [x_1^{(t)}, ..., x_i^{(t+1)},... x_{n-1}^{(t)}].$\n",
    "\n",
    "*Blocked Gibbs sampling* treats some groups of variables in blocks and samples an update to them at the same time.  This is useful for example if that group of variables is highly correlated.  Considering them separately would then result in missing this structure. We will not consider blocking in this notebook.\n",
    "\n",
    "Good introductory reading on Gibbs sampling is for example in Casella and George [2].\n",
    "\n",
    "All of the above procedures correspond to valid Gibbs sampling algorithms, so there is considerable flexibility in the design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A summary and comparison: Metropolis vs. Gibbs\n",
    "A (biased) summary of the differences between Metropolis and Gibbs sampling could go as follows.  While deriving a Gibbs sampler is more work, as a result the Gibbs sampler actually has better guidance in selecting new values for random variables.  Where Metropolis performs blind guesses and relies on the accept/reject step to check if the step is good, the Gibbs sampler samples directly from the conditional distribution and thus is guided in it's choice of next value by both the data and prior (as applicable to the current random variable).\n",
    "\n",
    "We can also see [Gibbs sampling as a Metropolis-type proposal](https://en.wikipedia.org/wiki/Gibbs_sampling#Introduction) (but in a more general incarnation Metropolis-Hastings) which is always accepted.  There are some interesting connections between Gibbs and Metropolis that allow embedding one in the other, which will become useful later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to select a strategy?\n",
    "\n",
    "It is a natural question whether some of these strategies are better than others.  It's difficult to find information on these topics but the following considerations seem useful.\n",
    "\n",
    "**Blocked sampler** If some variables are highly correlated it makes sense to sample them together given the other variables. Thus if we imagine trying to use the Gibbs sampler on the 2D Gaussian with high correlation we have used previously, we see that being able to incorporate the correlation into the proposal would allow us to move diagonally instead of axis-aligned (per variable).\n",
    "\n",
    "**Random/systematic scan** there don't seem to be results preferring one or the other except for Andrieu 2016 [3] (!!), where it is shown that systematic scan is better than random scan in terms of reducing the variance of the estimator **if** the problem consists of two variables and discusses why the proof does not hold for more variables then that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Ising model\n",
    "A very popular example for the Gibbs algorithm is the [Ising model](https://en.wikipedia.org/wiki/Ising_model) which can be observed live for example on [this page](https://cs.stanford.edu/people/karpathy/visml/ising_example.html) [1].\n",
    "\n",
    "A simple version of an Ising model is a two-dimensional lattice of binary variables $x_i \\in \\{-1,+1\\}$ that are horizontally and vertically connected using pairwise factor potentials.  \n",
    "\n",
    "![Ising model](https://jgtechnologysolutions.files.wordpress.com/2017/02/ising.png?w=620)\n",
    "Image source: https://jgtechnologysolutions.org\n",
    "\n",
    "We may also apply a potential field $\\bf{b}$, which attract some elements of the Ising model toward 1 or toward -1.  The total *energy* of the field is given by the Hamiltonian and can then be written as:\n",
    "\n",
    "$$H(\\textbf{x}) = - J \\sum_{(i,j) \\in E} x_i x_j - J_b \\sum_{i \\in V} b_i x_i,$$\n",
    "\n",
    "where $J$ is the strength of the interactions, $J_b$ is the strength of the external field and $b_i$ are the desired values. The first sum is over edges $E$ connecting the elements (see figure below) and the other is over the elements $V$ themselves.\n",
    "\n",
    "We define the (unnormalized) distribution over states to be:\n",
    "\n",
    "$$\\pi(\\textbf{x}) = \\exp (- H(\\textbf{x}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\pi(x)$ distribution is our posterior that we wish to sample from (we didn't explictly build any priors or data likelihood - let's assume that the function above is the result of such considerations). Let's break down how the probability depends on a value of a fixed element $x_i$.\n",
    "\n",
    "Hence forth we will denote $E_i(x_i)$ as the part of the energy $E$ that depends on $x_i$ and $E_{-i}$ as the rest of the function. In Gibbs sampling we select one (or more) variables that we want to update and the rest of the model (here represented by $E_{-i}$ remains unchanged. For concreteness, we only select a single variable to update here. Note that $E = E_i(x_i) + E_{-i}$.\n",
    "\n",
    "For the purposes of analyzing the update, we will denote the neighbouring nodes $x_a, x_b, x_c, x_d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gibbs sampling, we need to compute $\\pi(x_i \\mid x_{-i})$ which can be computed as\n",
    "\n",
    "$$ \\pi(x_i = v \\mid x_{-i}) = \\frac{\\pi(x_i=v \\mid x_{-i})}{\\pi(x_i=+1 \\mid x_{-i}) + \\pi(x_i=-1 \\mid x_{-i})}.$$\n",
    "\n",
    "Where $v \\in \\{ -1, +1 \\}$.\n",
    "\n",
    "**Note** that here we casually sidestep the normalization problem. Normalization is intractable for the entire model $\\pi(x)$ but since here we restricted our analysis only to one variable, it's easy and is solved by the formula above, which returns a valid conditional distribution $\\pi(x_i = v \\mid x_{-i})$ even if $\\pi(x)$ is not normalized.\n",
    "\n",
    "These considerations lead us to consider $E_i(x_i)$ and $E_{-1}$.  Rewriting the equation in logs again, we get\n",
    "\n",
    "$$ \\pi(x_i = +1 \\mid x_{-i}) = \\frac{\\exp(E_i(x_i=+1) + E_{-i})}{\\exp(E_i(x_i=+1)+E_{-i}) + \\exp(E_i(x_i=+1)+E_{-i}) }$$\n",
    "\n",
    "from which we can factor and cancel out $E_{-i}$ to obtain\n",
    "\n",
    "$$ \\pi(x_i = +1 \\mid x_{-i}) = \\frac{\\exp(E_i(x_i=+1))}{\\exp(E_i(x_i=+1)) + \\exp(E_i(x_i=-1))}.$$\n",
    "\n",
    "**Note** that this results in a huge computational efficiency gain, we can evaluate the conditional with respect to only the neighbouring nodes as the state of $x_i$ is conditionally independent from the rest of the model given it's neighbors.  In effect, we can compute the posterior in O(1) time and update the entire state in $O(N)$ time where $N$ is the number of elements.\n",
    "\n",
    "We thus have\n",
    "\n",
    "$$E_i(x_i) = J(x_ix_a + x_ix_b + x_ix_c + x_ix_d) + J_bb_ix_i,$$\n",
    "\n",
    "which factorizes nicely\n",
    "\n",
    "$$E_i(x_i) = x_i \\left ( J (x_a + x_b + x_c + x_d) + J_bb_i \\right ),$$\n",
    "\n",
    "which makes the value extremely simple to compute for both options $x_i=+1$ and $x_i=-1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting it up\n",
    "Below we build the force field that will act on the system, a random state generator and a function that computes the Hamiltonian for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "# rows and columns\n",
    "rows, cols = 8, 8\n",
    "\n",
    "b = np.array([[-1, -1, -1, -1, -1, -1, -1, -1],\n",
    "              [-1, -1, -1, -1, -1, -1, -1, -1],\n",
    "              [-1, -1, +1, -1, +1, +1, -1, -1],\n",
    "              [-1, -1, +1, +1, +1, +1, -1, -1],\n",
    "              [-1, -1, +1, -1, +1, -1, -1, -1],\n",
    "              [-1, -1, +1, +1, +1, +1, -1, -1],\n",
    "              [-1, -1, -1, -1, -1, -1, -1, -1],\n",
    "              [-1, -1, -1, -1, -1, -1, -1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_state(prob_one):\n",
    "    X = np.where(nr.uniform(size=(8,8)) < 1. - prob_one, -1, +1)\n",
    "    return X\n",
    "\n",
    "X_init = random_state(0.5)\n",
    "X_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hamiltonian(X, b, J, Jb):\n",
    "    H = 0.0\n",
    "    \n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            # evaluate the E_i term for the actual value of X[r,c]\n",
    "            # sum over elements\n",
    "            H -= Jb * b[r,c] * X[r,c]\n",
    "            \n",
    "            # sum over edges\n",
    "            if r > 0:\n",
    "                H -= J * X[r-1,c] * X[r,c]\n",
    "            if c > 0:\n",
    "                H -= J * X[r, c-1] * X[r,c]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = compute_hamiltonian(X_init, b, 1., 1.)\n",
    "pi = np.exp(-H)\n",
    "H, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: derive the full conditional\n",
    "A key part of developing the Gibbs sampler is the function that computes the conditional distribution of $x_i$ given $x_{-i}$, or given all the other states.  In the following, write the function that computes this efficiently.  We supply a function that computes the value by definition but has terrible time complexity.\n",
    "\n",
    "To derive the more effective function, analyze how a change in the value of $x_i$ affects the posterior and what remains unchanged.  Only that part must be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_xrc_is_minus1_bad(X,b,r,c,J,Jb):\n",
    "    memory = X[r,c]\n",
    "    # compute conditional from definition\n",
    "    X[r,c] = +1.\n",
    "    pi_x_plus1 = np.exp(-compute_hamiltonian(X, b, J, Jb))\n",
    "    \n",
    "    X[r,c] = -1\n",
    "    pi_x_minus1 = np.exp(-compute_hamiltonian(X, b, J, Jb))\n",
    "    \n",
    "    return pi_x_minus1 / (pi_x_minus1 + pi_x_plus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_xrc_is_minus1(X,b,r,c,J,Jb):\n",
    "\n",
    "    # EXERCISE: compute value proportional to p(x_[r,c] = 1|all other variables)\n",
    "    p_xrc_minus1 = 0.5\n",
    "    \n",
    "    # EXERCISE: compute value proportional to p(x_[r,c] = -1| all other variables)\n",
    "    p_xrc_plus1 = 0.5\n",
    "    \n",
    "    return p_xrc_minus1 / (p_xrc_minus1 + p_xrc_plus1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing your function\n",
    "The two functions below must give the same output given the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_conditional_xrc_is_minus1(X_init, b, 2, 1, 1., 0.5), compute_conditional_xrc_is_minus1_bad(X_init,b,2,1,1.,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run the sampler\n",
    "The function `run_gibbs_systematic_scan` below performs systematic scan Gibbs sampling.  Using your function, run the sampler a few times and examine the visualizations to see what happens under various field and connection strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gibbs_systematic_scan(X, b, J, Jb, steps=1):\n",
    "    # note that X is modified in place\n",
    "    for s in range(steps):\n",
    "        # pre-sample a bunch of uniform random numbers\n",
    "        random_buffer = np.random.uniform(size=(rows, cols))\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                cond_p_xi_minus1 = compute_conditional_xrc_is_minus1(X, b, r, c, J, Jb)\n",
    "                X[r,c] = -1. if random_buffer[r,c] < cond_p_xi_minus1 else +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstate = np.copy(X_init)\n",
    "run_gibbs_systematic_scan(Xstate, b, 1., 0.5)\n",
    "Xstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing samples\n",
    "Below we run the Gibbs sampler iteratively and display every second sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "steps_per_iter = 2\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "Xstate = random_state(0.1)\n",
    "for step in range(36):\n",
    "    plt.subplot(6,6,step+1)\n",
    "    plt.imshow(Xstate)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('$H({\\\\bf x})=$%g [%d]' % (compute_hamiltonian(Xstate, b, 0.5, 1.6), step*steps_per_iter))\n",
    "    run_gibbs_systematic_scan(Xstate, b, 0.8, 1.6, steps=steps_per_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate 1000 samples\n",
    "N = 1000\n",
    "X = random_state(0.5)\n",
    "Xs = np.zeros((N, rows, cols))\n",
    "for i in range(N):\n",
    "    # variable is modified in place\n",
    "    run_gibbs_systematic_scan(X, b, 0.3, 0.6)\n",
    "    Xs[i,:,:] = X\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.mean(Xs, axis=0))\n",
    "plt.title('Expected values')\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.clim([-1,1])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.std(Xs, axis=0))\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('Standard deviations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Build a `run_gibbs_random_scan` function to perform random scan Gibbs sampling, run it in place of `run_gibbs_systematic_scan` and observe whether there are any changes in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-within-Gibbs\n",
    "The Gibbs algorithm requires that we can derive and evaluate conditional probabilities for all variables.  This is impractical in many situations.  \n",
    "\n",
    "In such cases, it's possible to to sample with a design called Metropolis-within-Gibbs, where we combine Gibbs and Metropolis sampling.  Extra reading on designing hybrid sampling systems is for example in Tierney [4].  Here we only note that there is significant flexibility in constructing hybrid samplers and the following is just one example.\n",
    "\n",
    "Let's solve a simple mixture problem with two Gaussian mixtures that we want to fit a set of points $d_i, i=1,...,40$ in one dimension.\n",
    "\n",
    "$$\\begin{array}{rcl}\n",
    "   \\mu_0 &\\sim& {\\cal N}(0,1) \\\\\n",
    "   \\mu_1 &\\sim& {\\cal N}(0,1) \\\\\n",
    "   Z_i &\\sim& \\text{Bernoulli}(0.5) \\\\\n",
    "   d_i &\\sim& {\\cal N}(\\mu_0(1-Z_i) + \\mu_1 Z_i) \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Writing a Metropolis sampler for this model should be a breeze, but this time we will do something different: write a hybrid sampler that uses different methods of proposing different variables:\n",
    "\n",
    "- $\\mu_0, \\mu_1$ using Metropolis random walk (with accept/reject) and\n",
    "- $Z$ using Gibbs sampling (always accepted).\n",
    "\n",
    "If we cycle these two proposals, we have a valid hybrid sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(mu1, mu2, N):\n",
    "    return np.hstack([nr.randn(N) + mu1, nr.randn(N) + mu2])\n",
    "\n",
    "def log_normal(x, mu, sd):\n",
    "    return - np.log(sd) - 0.5 * (x - mu)**2/sd**2\n",
    "\n",
    "def log_prior(v):\n",
    "    return log_normal(v['mu0'], 0, 10) + log_normal(v['mu0'], 0, 10) + len(v['Z']) * np.log(0.5)\n",
    "\n",
    "def log_likelihood(v, data):\n",
    "    Z = v['Z']\n",
    "    return np.sum(log_normal(data, v['mu0'] * (1-Z) + v['mu1'] * Z, 1.0))\n",
    "\n",
    "def log_posterior(v, data):\n",
    "    # add a factor potential that forces v['mu0'] <= v['mu1']\n",
    "    ordering_potential = -np.inf if v['mu0'] > v['mu1'] else 0.\n",
    "    return log_prior(v) + log_likelihood(v, data) + ordering_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make the problem easy to visualize\n",
    "N = 20\n",
    "true_mu0, true_mu1 = 2.0, 6.0\n",
    "data = generate_data(true_mu0, true_mu1, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[:N], hist=False, rug=True)\n",
    "sns.distplot(data[N:], hist=False, rug=True)\n",
    "plt.title('Density of underlying data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_init = {\n",
    "    'mu0': nr.randn() * 10,\n",
    "    'mu1': nr.randn() * 10,\n",
    "    'Z' : np.where(nr.rand(2*N) < 0.5, 0, 1)\n",
    "}\n",
    "\n",
    "# ensure ordering holds\n",
    "if v_init['mu1'] < v_init['mu0']:\n",
    "    v_init['mu0'], v_init['mu1'] = v_init['mu1'], v_init['mu0']\n",
    "\n",
    "v_init, log_posterior(v_init, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior(v_init), log_likelihood(v_init, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(v):\n",
    "    global data\n",
    "    Z=v['Z']    \n",
    "    plt.plot([v['mu0']], [0.1], 'go')\n",
    "    plt.plot([v['mu1']], [0.1], 'ro')\n",
    "    sns.distplot(data[Z==0], hist=False, rug=True)\n",
    "    sns.distplot(data[Z==1], hist=False, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state(v_init)\n",
    "plt.title('Initial state');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_mus(v, logp):\n",
    "    v_prime = { 'mu0' : v['mu0'] + nr.randn() * 0.4,\n",
    "                'mu1' : v['mu1'] + nr.randn() * 0.4,\n",
    "                'Z' : v['Z']\n",
    "              }\n",
    "    \n",
    "    logp_prime = log_posterior(v_prime, data)\n",
    "    if logp_prime - logp > np.log(nr.rand()):\n",
    "        return v_prime, logp_prime, True\n",
    "    else:\n",
    "        return v, logp, False\n",
    "    \n",
    "    \n",
    "def propose_Z_metropolis(v, logp):    \n",
    "    Z = v['Z']\n",
    "    flips = nr.uniform(size=Z.shape) < 0.1\n",
    "    Z_prime = flips * (1-Z) + (1-flips)*Z\n",
    "    \n",
    "    v_prime = {\n",
    "        'mu0' : v['mu0'],\n",
    "        'mu1' : v['mu1'],\n",
    "        'Z' : Z_prime\n",
    "    }\n",
    "\n",
    "    logp_prime = log_posterior(v_prime, data)\n",
    "    if logp_prime - logp > np.log(nr.rand()):\n",
    "        return v_prime, logp_prime, True\n",
    "    else:\n",
    "        return v, logp, False\n",
    "        \n",
    "\n",
    "def propose_Z_gibbs(v, logp):\n",
    "    mu0, mu1, Z = v['mu0'], v['mu1'], v['Z']\n",
    "    \n",
    "    # 1. compute for each Z_i P(Z_i|all other variables)\n",
    "    # 2. sample from this conditional to obtain Znew, the new values for Z\n",
    "    \n",
    "    # not a good guess, replace with Gibbs sampler\n",
    "    Z_new = np.zeros_like(v['Z'])\n",
    "\n",
    "    v_prime = {\n",
    "        'mu0' : v['mu0'],\n",
    "        'mu1' : v['mu1'],\n",
    "        'Z' : Z_new\n",
    "    }\n",
    "    \n",
    "    return v_prime, log_posterior(v_prime, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "The sampler below uses two Metropolis steps in sequence to sample from the $\\mu_{0,1}$ and from $Z$.  There is a block that is commented out with the function `propose_Z_gibbs` that you should uncomment (after writing the function that is).\n",
    "\n",
    "1. Compare the number of steps required for convergence using Metropolis and using the hybrid sampler. The number of samples is intentionally set to a low number (100) to display the differences.\n",
    "2. Run the `propose_Z_gibbs` function a few times yourself while printing out the state and note that the proposed `Z` values match the data very well compared to the random guesses in `propose_Z_metropolis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_within_gibbs(v_init, n, status_period = None):\n",
    "    global data\n",
    "    \n",
    "    v, logp = v_init, log_posterior(v_init, data)\n",
    "    states, states_logp = [v_init], [logp]\n",
    "    was_accept1, was_accept2 = [], []\n",
    "    \n",
    "    if status_period is None:\n",
    "        status_period = n // 10\n",
    "    \n",
    "    for i in range(1,n):\n",
    "                \n",
    "        # propose mu1 and mu2 via a Metropolis step\n",
    "        v1, logp_v1, accept1 = propose_mus(v, logp)\n",
    "        was_accept1.append(accept1)\n",
    "\n",
    "        # EXERCISE: the two blocks below sample Z, currently we have an inefficient Metropolis sampler,\n",
    "        # but we would like to have a sleek Gibbs sampler - uncomment the gibbs block below and comment\n",
    "        # the Metropolis block when you have your Gibbs proposal.\n",
    "        \n",
    "        # now v1, logp_v1 are either v, logp if a reject occured or a new state\n",
    "        v2, logp_v2, accept2 = propose_Z_metropolis(v1, logp_v1)\n",
    "        was_accept2.append(accept2)\n",
    "        \n",
    "        #v2, logp_v2 = propose_Z_gibbs(v1, logp_v1)\n",
    "        #was_accept2.append(True)\n",
    "        \n",
    "        # append whatever came out\n",
    "        states.append(v2)\n",
    "        states_logp.append(logp_v2)\n",
    "        \n",
    "        v, logp = v2, logp_v2\n",
    "            \n",
    "        if i > 1 and i % status_period == 0:\n",
    "            print('Stats @ %d: accept1_ratio=%g accept2_ratio=%g avg_logp=%g' %\n",
    "                  (i, float(np.sum(was_accept1[-status_period:]))/status_period,\n",
    "                   float(np.sum(was_accept2[-status_period:]))/status_period,\n",
    "                   np.mean(states_logp[-status_period:])))\n",
    "            \n",
    "    return states, float(np.sum(was_accept1)) / n, float(np.sum(was_accept2)) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, ar1, ar2 = metropolis_within_gibbs(v_init, 100, status_period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0s = np.array([s['mu0'] for s in states])\n",
    "mu1s = np.array([s['mu1'] for s in states])\n",
    "Zs = np.vstack([s['Z'] for s in states])\n",
    "\n",
    "burn_in = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.subplot(3,2,1)\n",
    "sns.kdeplot(mu0s[burn_in:]);\n",
    "plt.ylabel('$\\\\mu_0$')\n",
    "plt.subplot(3,2,2)\n",
    "plt.plot(mu0s)\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "sns.kdeplot(mu1s[burn_in:]);\n",
    "plt.ylabel('$\\\\mu_1$')\n",
    "plt.subplot(3,2,4)\n",
    "plt.plot(mu1s)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.errorbar(np.arange(2*N), np.mean(Zs, axis=0), yerr=np.std(Zs, axis=0))\n",
    "plt.xlim([-1,2*N])\n",
    "plt.xticks(range(2*N))\n",
    "plt.ylabel('Z');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mu0: %g +- %g [true value: %g]' % (np.mean(mu0s[burn_in:]), np.std(mu0s[burn_in:]), true_mu0))\n",
    "print('mu1: %g +- %g [true value: %g]' % (np.mean(mu1s[burn_in:]), np.std(mu1s[burn_in:]), true_mu1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise [advanced]\n",
    "\n",
    "For example in notebook 3g, while we can derive the conditional probability for the latent indicator variables $Z_{i,j}$ it is very difficult to derive the conditionals for the other variables.\n",
    "\n",
    "Build a Metropolis-within-Gibbs scheme for the example in notebook 3g (build on your pure Metropolis solution) and note how the $Z$ variables that are sampled directly from the full conditional very nicely follow the likelihood.  Compare this strategy to the blind proposals in your Metropolis method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Andrej Karpathy, Stanford. [Ising model example](https://cs.stanford.edu/people/karpathy/visml/ising_example.html).\n",
    "2. G Casella and G. Edwards, “Explaining the Gibbs sampler,” The American Statistician, 1992.\n",
    "3. C Andrieu, “On random- and systematic-scan samplers,” Biometrika, vol. 103, no. 3, pp. 719–726, 2016.\n",
    "4. L. Tierney, “Markov chains for exploring posterior distributions,” the Annals of Statistics, 1994."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
